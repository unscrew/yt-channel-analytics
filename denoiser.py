#!/usr/bin/env python3
"""
STT Transcript ë…¸ì´ì¦ˆ ì œê±° ìŠ¤í¬ë¦½íŠ¸
Whisper ë“± ìŒì„±ì¸ì‹ ê²°ê³¼ë¬¼ ì •ì œ
"""

import argparse
import re
import os


def remove_repeated_interjections(text: str) -> str:
    """
    ë°˜ë³µë˜ëŠ” ê°íƒ„ì‚¬/ì¶”ì„ìƒˆ ì œê±°
    ì˜ˆ: "ì•„... ì•„... ì•„..." â†’ "ì•„"
    """
    # 1. ì ìœ¼ë¡œ ì—°ê²°ëœ ë°˜ë³µ (ì•„..., ì–´..., ìŒ...)
    text = re.sub(r'([ì•„ì–´ìŒì˜¤ìš°ì—]\.\.\.\s*){2,}', r'\1', text)
    
    # 2. ê°™ì€ ê°íƒ„ì‚¬ ì—°ì† ë°˜ë³µ
    text = re.sub(r'\b([ì•„ì–´ìŒì˜¤ìš°ì—])\s+\1(\s+\1)+\b', r'\1', text)
    
    return text


def remove_repeated_words(text: str) -> str:
    """
    ê°™ì€ ë‹¨ì–´ ì—°ì† ë°˜ë³µ ì œê±°
    ì˜ˆ: "ì´ê±° ì´ê±° ì´ê±°" â†’ "ì´ê±°"
    """
    # 2-3íšŒ ì—°ì† ë°˜ë³µ (2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ)
    text = re.sub(r'\b(\w{2,})(\s+\1){1,}\b', r'\1', text)
    
    return text


def remove_filler_words_excessive(text: str) -> str:
    """
    ê³¼ë„í•œ ì¶”ì„ìƒˆ ì œê±°
    ì˜ˆ: "ë„¤ë„¤ë„¤ë„¤" â†’ "ë„¤"
    """
    fillers = ['ë„¤ë„¤', 'ì‘ì‘', 'ì–´ì–´', 'ìŒìŒ', 'ê·¸ì¹˜ê·¸ì¹˜', 'ë§ì•„ë§ì•„']
    
    for filler in fillers:
        # ì—°ì† ë°˜ë³µ ì°¾ê¸°
        pattern = f'({re.escape(filler)})+'
        text = re.sub(pattern, filler, text)
    
    return text


def remove_stuttering(text: str) -> str:
    """
    ë§ë”ë“¬ íŒ¨í„´ ì œê±°
    ì˜ˆ: "ì €.. ì €ëŠ”" â†’ "ì €ëŠ”"
    """
    # ë‹¨ì–´ ì‹œì‘ ë°˜ë³µ (ì²« ê¸€ì ë˜ëŠ” ì²« ìŒì ˆ ë°˜ë³µ)
    text = re.sub(r'\b(\w{1,2})\.\.\s+\1(\w+)', r'\1\2', text)
    
    return text


def clean_punctuation(text: str) -> str:
    """
    êµ¬ë‘ì  ì •ë¦¬
    """
    # ì—°ì†ëœ ë§ˆì¹¨í‘œ/ì‰¼í‘œ ì •ë¦¬
    text = re.sub(r'\.{4,}', '...', text)
    text = re.sub(r',{2,}', ',', text)
    
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\s+([,.!?])', r'\1', text)
    
    return text


def remove_noise_patterns(text: str) -> str:
    """
    STT íŠ¹ìœ ì˜ ë…¸ì´ì¦ˆ íŒ¨í„´ ì œê±°
    """
    # 1. ì˜ë¯¸ì—†ëŠ” ì§§ì€ ë°˜ë³µ
    text = re.sub(r'\b(\w)\s+\1\s+\1\b', r'\1', text)
    
    # 2. ê´„í˜¸ ì•ˆì˜ ì†ŒìŒ í‘œê¸° ì œê±°
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\(.*?\)', '', text)
    
    # 3. íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° (ìˆì„ ê²½ìš°)
    text = re.sub(r'\d{1,2}:\d{2}:\d{2}', '', text)
    text = re.sub(r'\d{1,2}:\d{2}', '', text)
    
    return text


def normalize_spacing(text: str) -> str:
    """
    ë„ì–´ì“°ê¸° ì •ê·œí™”
    """
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    
    # ë¬¸ì¥ ì‹œì‘/ë ê³µë°± ì œê±°
    text = text.strip()
    
    # ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r'\n\s*\n', '\n\n', text)
    
    return text


def preserve_metadata(text: str) -> tuple:
    """
    ë©”íƒ€ë°ì´í„° ë¶„ë¦¬ ë° ë³´ì¡´
    (Video ID, Title, Model ë“±)
    """
    lines = text.split('\n')
    metadata_lines = []
    content_start = 0
    
    for i, line in enumerate(lines):
        # ë©”íƒ€ë°ì´í„° íŒ¨í„´ ê°ì§€
        if ':' in line and i < 10:
            if any(key in line for key in ['Video ID', 'Title', 'Model', 'Duration']):
                metadata_lines.append(line)
                content_start = i + 1
            elif line.strip() == '-' * len(line.strip()):
                metadata_lines.append(line)
                content_start = i + 1
                break
    
    metadata = '\n'.join(metadata_lines)
    content = '\n'.join(lines[content_start:])
    
    return metadata, content


def denoise_transcript(text: str, aggressive: bool = False) -> str:
    """
    ì¢…í•© ë…¸ì´ì¦ˆ ì œê±° íŒŒì´í”„ë¼ì¸
    
    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
        aggressive: Trueë©´ ë” ê°•ë ¥í•œ ì œê±° (ì¶”ì„ìƒˆê¹Œì§€)
    
    Returns:
        ì •ì œëœ í…ìŠ¤íŠ¸
    """
    # ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
    metadata, content = preserve_metadata(text)
    
    # ë…¸ì´ì¦ˆ ì œê±° íŒŒì´í”„ë¼ì¸
    content = remove_repeated_interjections(content)
    content = remove_repeated_words(content)
    content = remove_filler_words_excessive(content)
    content = remove_stuttering(content)
    content = remove_noise_patterns(content)
    content = clean_punctuation(content)
    content = normalize_spacing(content)
    
    # aggressive ëª¨ë“œ: ì¶”ì„ìƒˆ ë‹¨ì–´ë„ ì œê±°
    if aggressive:
        fillers_to_remove = [
            r'\bì•„\s+', r'\bì–´\s+', r'\bìŒ\s+', r'\bìœ¼\s+',
            r'\bê·¸\s+', r'\bì´ì œ\s+', r'\bì¢€\s+', r'\bë­\s+'
        ]
        for pattern in fillers_to_remove:
            content = re.sub(pattern, '', content)
        content = normalize_spacing(content)
    
    # ë©”íƒ€ë°ì´í„° ë³µì›
    if metadata:
        return metadata + '\n\n' + content
    else:
        return content


def process_file(input_file: str, aggressive: bool = False, verbose: bool = True):
    """
    íŒŒì¼ ì²˜ë¦¬ ë° ì €ì¥
    """
    # ì…ë ¥ íŒŒì¼ ì½ê¸°
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            original_text = f.read()
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return None
    
    original_length = len(original_text)
    
    if verbose:
        print(f"\nğŸ“„ ì…ë ¥: {input_file}")
        print(f"âœ“ ì›ë³¸ ê¸¸ì´: {original_length:,} ê¸€ì")
    
    # ë…¸ì´ì¦ˆ ì œê±°
    denoised_text = denoise_transcript(original_text, aggressive)
    denoised_length = len(denoised_text)
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    base_name = os.path.splitext(input_file)[0]
    output_file = f"{base_name}_denoised.txt"
    
    # ì €ì¥
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(denoised_text)
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None
    
    # ê²°ê³¼ ì¶œë ¥
    if verbose:
        removed = original_length - denoised_length
        reduction_pct = (removed / original_length * 100) if original_length > 0 else 0
        
        print(f"âœ“ ì •ì œ í›„ ê¸¸ì´: {denoised_length:,} ê¸€ì")
        print(f"âœ“ ì œê±°ëœ ë…¸ì´ì¦ˆ: {removed:,} ê¸€ì ({reduction_pct:.1f}%)")
        print(f"ğŸ’¾ ì¶œë ¥: {output_file}")
        
        # ìƒ˜í”Œ ë¹„êµ
        print("\n" + "=" * 80)
        print("ğŸ“Š Before/After ë¹„êµ (ì²˜ìŒ 200ì):")
        print("=" * 80)
        
        # ë©”íƒ€ë°ì´í„° ì œê±°í•˜ê³  ë¹„êµ
        _, original_content = preserve_metadata(original_text)
        _, denoised_content = preserve_metadata(denoised_text)
        
        print("\n[Before]")
        print(original_content[:200].strip())
        print("\n[After]")
        print(denoised_content[:200].strip())
        print("\n" + "=" * 80)
    
    return output_file


def main():
    parser = argparse.ArgumentParser(
        description='STT ìë§‰ ë…¸ì´ì¦ˆ ì œê±° ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python denoise_stt.py H5lz6_hqCNw_whisper_transcript.txt
  python denoise_stt.py input.txt --aggressive
  python denoise_stt.py input.txt --quiet
  
ì œê±°ë˜ëŠ” ë…¸ì´ì¦ˆ:
  âœ“ ë°˜ë³µ ê°íƒ„ì‚¬ (ì•„... ì•„... ì•„...)
  âœ“ ì—°ì† ë°˜ë³µ ë‹¨ì–´ (ì´ê±° ì´ê±° ì´ê±°)
  âœ“ ê³¼ë„í•œ ì¶”ì„ìƒˆ (ë„¤ë„¤ë„¤ë„¤)
  âœ“ ë§ë”ë“¬ (ì €.. ì €ëŠ”)
  âœ“ ë¶ˆí•„ìš”í•œ ê³µë°±/êµ¬ë‘ì 
  
ì¶œë ¥:
  {ì…ë ¥íŒŒì¼ëª…}_denoised.txt
        """
    )
    
    parser.add_argument(
        'input_file',
        help='ì…ë ¥ STT ìë§‰ íŒŒì¼'
    )
    
    parser.add_argument(
        '--aggressive',
        '-a',
        action='store_true',
        help='ê°•ë ¥ ëª¨ë“œ (ì¶”ì„ìƒˆ ë‹¨ì–´ë„ ì œê±°)'
    )
    
    parser.add_argument(
        '--quiet',
        '-q',
        action='store_true',
        help='ì¡°ìš©íˆ ì‹¤í–‰ (ê²°ê³¼ë§Œ ì¶œë ¥)'
    )
    
    args = parser.parse_args()
    
    if not args.quiet:
        print("=" * 80)
        print("ğŸ§¹ STT ìë§‰ ë…¸ì´ì¦ˆ ì œê±°")
        print("=" * 80)
    
    output_file = process_file(
        args.input_file,
        aggressive=args.aggressive,
        verbose=not args.quiet
    )
    
    if output_file:
        if not args.quiet:
            print("\nâœ… ì™„ë£Œ!")
        else:
            print(output_file)
    else:
        print("\nâŒ ì‹¤íŒ¨!")
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())